{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d8289d-b45d-4385-8798-5e9c7cf78f83",
   "metadata": {},
   "source": [
    "# Ensemble notebook\n",
    "Takes the pickles made in the evaluation notebook to average probabilities together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdb6a41-f65b-422a-8937-6574bd89932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext tensorboard\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba4b7199-b10e-4f05-aed5-5187e91ed955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from collections import OrderedDict\n",
    "import SimpleITK as sitk\n",
    "#import logging\n",
    "#logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "\n",
    "import pickle, subprocess\n",
    "import scipy\n",
    "import sklearn\n",
    "import csv\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "#import initial_ml as iml\n",
    "from gbm_project import data_prep as dp\n",
    "from gbm_project.pytorch.run_model_torch import RunModel\n",
    "from gbm_project.pytorch import resnet_spottune as rs\n",
    "from MedicalNet.models import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672bda66-fb93-4df7-bac8-c2cf351b9c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "print(f\"using {device} device\")\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "#torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a04e5d-1eb8-4f2d-9370-775ecf1db98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the metrics used in the evaluation, can add or remove as desired\n",
    "acc_fn = torchmetrics.classification.BinaryAccuracy(threshold=0.5)\n",
    "auc_fn = torchmetrics.classification.BinaryAUROC()\n",
    "spe_fn = torchmetrics.classification.BinarySpecificity()\n",
    "pre_fn = torchmetrics.classification.BinaryPrecision()\n",
    "sen_fn = torchmetrics.classification.BinaryRecall()\n",
    "f1_fn = torchmetrics.classification.BinaryF1Score()\n",
    "confusion = torchmetrics.classification.BinaryConfusionMatrix()\n",
    "roc_fn = torchmetrics.classification.BinaryROC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04f0e71-4511-4841-895a-676facd6da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resets metric functions, should be run for each successive evaluation of probabilities as values entered into functions are persistent until reset\n",
    "acc_fn.reset()\n",
    "auc_fn.reset()\n",
    "spe_fn.reset()\n",
    "sen_fn.reset()\n",
    "pre_fn.reset()\n",
    "f1_fn.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4902b11b-5d29-4689-98d0-d5e7dcc75920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull probability values from pkl files\n",
    "# results_spottune is the location of the probability pickles\n",
    "b_string_file_names = subprocess.check_output('ls -1 ./results_spottune')\n",
    "file_name_list = b_string_file_names.decode().split('\\n')\n",
    "cwd = './results_spottune'\n",
    "\n",
    "test_folds = {}\n",
    "for name in file_name_list:\n",
    "    if 'test' in name:\n",
    "        with open(os.path.join(cwd,name), 'rb') as f:\n",
    "            test_folds[name.replace('_test.pkl','')] = pickle.load(f)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2145e5e1-54be-49b5-83d9-1e73225c6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lists form up the basis for various ensembles\n",
    "# each list corresponds to an ensemble\n",
    "dsc_mods = [\n",
    "            'DSC_ap-rCBV',\n",
    "            'DSC_PH',\n",
    "            'DSC_PSR',\n",
    "           ]\n",
    "struct_mods = [\n",
    "               'T2',\n",
    "               'FLAIR',\n",
    "               'T1',\n",
    "               'T1GD',\n",
    "              ]\n",
    "dti_mods = [\n",
    "            'DTI_AD',\n",
    "            'DTI_FA',\n",
    "            'DTI_RD',\n",
    "            'DTI_TR',\n",
    "           ]\n",
    "dsc_struct = [\n",
    "            'DSC_ap-rCBV',\n",
    "            'DSC_PH',\n",
    "            'DSC_PSR',\n",
    "            'T2',\n",
    "            'FLAIR',\n",
    "            'T1',\n",
    "            'T1GD',\n",
    "             ]\n",
    "dsc_dti = [\n",
    "            'DSC_ap-rCBV',\n",
    "            'DSC_PH',\n",
    "            'DSC_PSR',\n",
    "            'DTI_AD',\n",
    "            'DTI_FA',\n",
    "            'DTI_RD',\n",
    "            'DTI_TR',\n",
    "          ]\n",
    "all_mods = [\n",
    "            'DSC_ap-rCBV',\n",
    "            'DSC_PH',\n",
    "            'DSC_PSR',\n",
    "            'DTI_AD',\n",
    "            'DTI_FA',\n",
    "            'DTI_RD',\n",
    "            'DTI_TR',\n",
    "            'T2',\n",
    "            'FLAIR',\n",
    "            'T1',\n",
    "            'T1GD',\n",
    "          ]\n",
    "dti_struct = [\n",
    "            'DTI_AD',\n",
    "            'DTI_FA',\n",
    "            'DTI_RD',\n",
    "            'DTI_TR',\n",
    "            'T2',\n",
    "            'FLAIR',\n",
    "            'T1',\n",
    "            'T1GD',\n",
    "          ]\n",
    "\n",
    "# The name of the model to make ensembles of, refers to a specific training\n",
    "trainings = [\n",
    "             'M_metric',\n",
    "            ]\n",
    "\n",
    "training_sets = {}\n",
    "\n",
    "# sets up the models that go into each ensemble\n",
    "# i.e. DSC_DTI will grab the models corresponding to all of the DSC and DTI derivatives\n",
    "for t in trainings:\n",
    "    training_sets[f\"spottune_DSC_{t}\"] = [f\"spottune_{m}_{t}\" for m in dsc_mods]\n",
    "    training_sets[f\"spottune_struct_{t}\"] = [f\"spottune_{m}_{t}\" for m in struct_mods]\n",
    "    training_sets[f\"spottune_DTI_{t}\"] = [f\"spottune_{m}_{t}\" for m in dti_mods]\n",
    "    training_sets[f\"spottune_all_{t}\"] = [f\"spottune_{m}_{t}_comb_all\" for m in all_mods]\n",
    "    training_sets[f\"spottune_DSC_DTI_{t}\"] = [f\"spottune_{m}_{t}_comb_dti\" for m in dsc_dti]\n",
    "    training_sets[f\"spottune_DSC_struct_{t}\"] = [f\"spottune_{m}_{t}_comb_struct\" for m in dsc_struct]\n",
    "    training_sets[f\"spottune_DTI_struct_{t}\"] = [f\"spottune_{m}_{t}_comb_dti_struct\" for m in dti_struct]\n",
    "    #training_sets[f\"transfer_DSC_{t}\"] = [f\"transfer_{m}_{t}\" for m in dsc_mods]\n",
    "    #training_sets[f\"transfer_DTI_{t}\"] = [f\"transfer_{m}_{t}\" for m in dti_mods]\n",
    "    #training_sets[f\"transfer_struct_{t}\"] = [f\"transfer_{m}_{t}\" for m in struct_mods]\n",
    "    #training_sets[f\"transfer_all_{t}\"] = [f\"transfer_{m}_{t}_comb_all\" for m in all_mods]\n",
    "    #training_sets[f\"transfer_DSC_DTI_{t}\"] = [f\"transfer_{m}_{t}_comb_dti\" for m in dsc_dti]\n",
    "    #training_sets[f\"transfer_DSC_struct_{t}\"] = [f\"transfer_{m}_{t}_comb_struct\" for m in dsc_struct]\n",
    "    #training_sets[f\"transfer_DTI_struct_{t}\"] = [f\"transfer_{m}_{t}_comb_dti_struct\" for m in dti_struct]\n",
    "    #training_sets[f\"random_DSC_{t}\"] = [f\"random_{m}_{t}\" for m in dsc_mods]\n",
    "    #training_sets[f\"random_DTI_{t}\"] = [f\"random_{m}_{t}\" for m in dti_mods]\n",
    "    #training_sets[f\"random_struct_{t}\"] = [f\"random_{m}_{t}\" for m in struct_mods]\n",
    "    #training_sets[f\"random_all_{t}\"] = [f\"random_{m}_{t}_comb_all\" for m in all_mods]\n",
    "    #training_sets[f\"random_DSC_DTI_{t}\"] = [f\"random_{m}_{t}_comb_dti\" for m in dsc_dti]\n",
    "    #training_sets[f\"random_DSC_struct_{t}\"] = [f\"random_{m}_{t}_comb_struct\" for m in dsc_struct]\n",
    "    #training_sets[f\"random_DTI_struct_{t}\"] = [f\"random_{m}_{t}_comb_dti_struct\" for m in dti_struct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb6880c-7692-418e-a504-e165a6cc956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the DTI and struct modalitites have more patients, these lines grab only those patients that are common to the DSC modalities in the testing dataset, dropping extra patients\n",
    "# the 'spottune_...' strings reference a placeholder model for each modality, replace as necessary with your own model\n",
    "dsc_pats = test_folds['spottune_DSC_PH_M_metric']['fold_0'][0]\n",
    "dti_pats = test_folds['spottune_DTI_AD_M_metric']['fold_0'][0]\n",
    "struct_pats = test_folds['spottune_T2_M_metric']['fold_0'][0]\n",
    "\n",
    "# the locations of the common patients\n",
    "dti_locs = [dti_pats.get_loc(pat) for pat in dsc_pats]\n",
    "struct_locs = [struct_pats.get_loc(pat) for pat in dsc_pats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01213cf4-c157-4098-9051-5e342d5d1a39",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the average probabilities for each fold for the testing dataset\n",
    "# These are averaging the 100 GS samplings into one set of probabilities for each fold\n",
    "\n",
    "test_fold_averages = {}\n",
    "fold_list = ['fold_0',\n",
    "             'fold_1',\n",
    "             'fold_2',\n",
    "             'fold_3',\n",
    "             'fold_4'\n",
    "            ]\n",
    "for training in test_folds:\n",
    "    running_avg = []\n",
    "    dsc_dti_running_avg = []\n",
    "    dsc_struct_running_avg = []\n",
    "    dti_struct_running_avg = []\n",
    "    val_running_avg = []\n",
    "    for i, fold in enumerate(fold_list):\n",
    "        if fold not in test_folds[training]:\n",
    "            print(f\"skipping {fold} for training: {training}\")\n",
    "            continue\n",
    "        running_avg.append(np.average(test_folds[training][f\"{fold}\"][1][:,0], axis=0))\n",
    "        if 'DTI' in training:\n",
    "            dsc_dti_running_avg.append(np.average(test_folds[training][f\"{fold}\"][1][:,0][:, dti_locs], axis=0))\n",
    "            dti_struct_running_avg.append(np.average(test_folds[training][f\"{fold}\"][1][:,0][:, dti_locs], axis=0))\n",
    "        if np.any([t in training for t in ['_T2_', '_FLAIR_', '_T1_', '_T1GD_']]):\n",
    "            if 'DSC' in training: continue\n",
    "            dsc_struct_running_avg.append(np.average(test_folds[training][f\"{fold}\"][1][:,0][:, struct_locs], axis=0))\n",
    "            dti_struct_running_avg.append(np.average(test_folds[training][f\"{fold}\"][1][:,0][:, struct_locs], axis=0))\n",
    "\n",
    "    # averaging probabilities between each fold\n",
    "    test_fold_averages[training] = np.mean(running_avg, axis=0)\n",
    "    if 'DSC' in training:\n",
    "        test_fold_averages[f\"{training}_comb_dti\"] = np.mean(running_avg, axis=0) \n",
    "        test_fold_averages[f\"{training}_comb_struct\"] = np.mean(running_avg, axis=0) \n",
    "        test_fold_averages[f\"{training}_comb_all\"] = np.mean(running_avg, axis=0) \n",
    "    if np.any(dsc_dti_running_avg): \n",
    "        test_fold_averages[f\"{training}_comb_dti\"] = np.mean(dsc_dti_running_avg, axis=0)\n",
    "        test_fold_averages[f\"{training}_comb_all\"] = np.mean(dsc_dti_running_avg, axis=0)\n",
    "    if np.any(dsc_struct_running_avg): \n",
    "        test_fold_averages[f\"{training}_comb_struct\"] = np.mean(dsc_struct_running_avg, axis=0)\n",
    "        test_fold_averages[f\"{training}_comb_all\"] = np.mean(dsc_struct_running_avg, axis=0)\n",
    "    if np.any(dti_struct_running_avg): \n",
    "        test_fold_averages[f\"{training}_comb_dti_struct\"] = np.mean(dti_struct_running_avg, axis=0)\n",
    "    val_fold_averages[training] = val_running_avg\n",
    "\n",
    "# averaging probabilities between modalities\n",
    "for s in training_sets.keys():\n",
    "    test_mean_probs = [test_fold_averages[t] for t in training_sets[s]]\n",
    "    test_fold_averages[f\"{s}\"] = np.mean(test_mean_probs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72be0744-41e8-4f48-881d-73c1880eaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes extraneous items that were used for intermediate combination steps\n",
    "test_fold_averages = {k:v for k,v in test_fold_averages.items() if 'comb' not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d9b06-5f3b-4b81-87c6-65495dbb94b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculation of performance metrics\n",
    "# saved to 'test_results...' file\n",
    "\n",
    "metrics_avg = {}\n",
    "for training in test_fold_averages:\n",
    "    target = []\n",
    "    print(training)\n",
    "    # get the target values for the testing dataset\n",
    "    try:\n",
    "        target = test_folds[training]['fold_0'][1][:,1][0]\n",
    "    except:\n",
    "        # the targets are all the same, but requires a different string to pull the target from the correct location depending on the ensemble name\n",
    "        if 'DSC_DTI' in training:\n",
    "            target = test_folds[training.replace('DSC_DTI', 'DSC_PH')]['fold_0'][1][:,1][0]\n",
    "        elif 'DSC_struct' in training:\n",
    "            target = test_folds[training.replace('DSC_struct', 'DSC_PH')]['fold_0'][1][:,1][0] \n",
    "        elif 'DTI_struct' in training:\n",
    "            target = test_folds[training.replace('DTI_struct', 'DSC_PH')]['fold_0'][1][:,1][0] \n",
    "        elif 'DSC_splits' in training:\n",
    "            target = test_folds[training.replace('DSC_splits', 'DSC_PH_plateau_0')]['fold_0'][1][:,1][0] \n",
    "        elif 'DSC' in training:\n",
    "            target = test_folds[training.replace('DSC','DSC_PH')]['fold_0'][1][:,1][0]\n",
    "        elif 'struct' in training:\n",
    "            target = test_folds[training.replace('struct','T2')]['fold_0'][1][:,1][0]\n",
    "        elif 'DTI' in training:\n",
    "            target = test_folds[training.replace('DTI','DTI_AD')]['fold_0'][1][:,1][0]\n",
    "        elif 'all' in training:\n",
    "            target = test_folds[training.replace('all', 'DSC_PH')]['fold_0'][1][:,1][0] \n",
    "            \n",
    "        print('changing target for combined modalities')\n",
    "\n",
    "    # calculates the different selected metrics\n",
    "    acc = acc_fn(torch.tensor(test_fold_averages[training]), torch.tensor(target))\n",
    "    auc = auc_fn(torch.tensor(test_fold_averages[training]), torch.tensor(target))\n",
    "    spe = spe_fn(torch.tensor(test_fold_averages[training]), torch.tensor(target))\n",
    "    pre = pre_fn(torch.tensor(test_fold_averages[training]), torch.tensor(target))\n",
    "    sen = sen_fn(torch.tensor(test_fold_averages[training]), torch.tensor(target))\n",
    "    f1 = f1_fn(torch.tensor(test_fold_averages[training]), torch.tensor(target))\n",
    "    metrics_avg[training] = (acc, auc, sen, spe, pre, f1)\n",
    "with open('test_results_09132023.csv', 'w', newline='') as f:\n",
    "    w = csv.writer(f)\n",
    "    f.write('model, ACC, AUC, SEN, SPE, PRE, F1')\n",
    "    f.write('\\r\\n')\n",
    "    for key, val in metrics_avg.items():\n",
    "        w.writerow([key] + [str(v) for v in val])\n",
    "    #w.writerows(metrics_avg.items())\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
